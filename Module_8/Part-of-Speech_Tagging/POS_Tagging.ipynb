{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI96mz0JpOUt",
        "outputId": "523a1e9b-7354-4217-ce57-8b56d71d4d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at QCRI/bert-base-multilingual-cased-pos-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "model_name = \"QCRI/bert-base-multilingual-cased-pos-english\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('treebank')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xbkwh9wSzOy",
        "outputId": "8bdb3004-33b7-472c-a77e-21ab2e5d8228"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
        "\n",
        "print(\"Number of samples:\", len(tagged_sentences))"
      ],
      "metadata": {
        "id": "yP0wZay5V-Qw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b3931f-cf03-468f-e16f-a29d981937dd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 3914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV2bz2fqHd0n",
        "outputId": "28cfb5f6-4686-4070-85b2-0f0c6258b05a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pierre', 'NNP'),\n",
              " ('Vinken', 'NNP'),\n",
              " (',', ','),\n",
              " ('61', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('old', 'JJ'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " ('join', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('board', 'NN'),\n",
              " ('as', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('nonexecutive', 'JJ'),\n",
              " ('director', 'NN'),\n",
              " ('Nov.', 'NNP'),\n",
              " ('29', 'CD'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, sentence_tags = [], []\n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tags = zip(*tagged_sentence)\n",
        "    sentences.append(sentence)\n",
        "    sentence_tags.append(tags)"
      ],
      "metadata": {
        "id": "ZzfXZE-XHf9P"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U-ZfRBrOfiy",
        "outputId": "48c42ce6-39ee-401f-dc28-70a7ce4cac6d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Pierre',\n",
              " 'Vinken',\n",
              " ',',\n",
              " '61',\n",
              " 'years',\n",
              " 'old',\n",
              " ',',\n",
              " 'will',\n",
              " 'join',\n",
              " 'the',\n",
              " 'board',\n",
              " 'as',\n",
              " 'a',\n",
              " 'nonexecutive',\n",
              " 'director',\n",
              " 'Nov.',\n",
              " '29',\n",
              " '.')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tags[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDfKu5qKOpdX",
        "outputId": "40199ab3-70ea-4f97-ffaa-dbd8bdb538ab"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('NNP',\n",
              " 'NNP',\n",
              " ',',\n",
              " 'CD',\n",
              " 'NNS',\n",
              " 'JJ',\n",
              " ',',\n",
              " 'MD',\n",
              " 'VB',\n",
              " 'DT',\n",
              " 'NN',\n",
              " 'IN',\n",
              " 'DT',\n",
              " 'JJ',\n",
              " 'NN',\n",
              " 'NNP',\n",
              " 'CD',\n",
              " '.')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6W1JuS8OtVU",
        "outputId": "f140fcb0-3120-4d15-e2e0-066439bcd050"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119547"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1IdtHiyRbe1",
        "outputId": "45752acf-1003-4d58-ae7f-812cd7d0c804"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=46, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_sentences, test_sentences, train_tags, test_tags = train_test_split(\n",
        "    sentences, sentence_tags, test_size=0.3\n",
        ")\n",
        "\n",
        "valid_sentences, test_sentences, valid_tags, test_tags = train_test_split(\n",
        "    test_sentences, test_tags, test_size=0.5\n",
        ")"
      ],
      "metadata": {
        "id": "9W8IPvKvRdFB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences), len(valid_sentences), len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HLP2fMlTbTC",
        "outputId": "e7389b4f-7b5b-465f-81e0-723873f93a64"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2739, 587, 588)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from typing import List\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8-wQ6GS3UaDV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = max([len(sentence) for sentence in sentences])"
      ],
      "metadata": {
        "id": "c1yt35OsVGgT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNDDG7Z_VLN0",
        "outputId": "a9f47d28-5d2d-4dba-c954-48b0e354fb57"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "271"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "label2id = defaultdict(int, model.config.label2id)\n",
        "id2label = {id: label for label, id in label2id.items()}"
      ],
      "metadata": {
        "id": "OE4AjVZmVrkT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8lkLhCxWQuZ",
        "outputId": "dd04d771-0ef2-4dda-9804-107611897b65"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'#': 7,\n",
              "             '$': 6,\n",
              "             \"''\": 5,\n",
              "             ',': 2,\n",
              "             '-LRB-': 17,\n",
              "             '-RRB-': 32,\n",
              "             '.': 4,\n",
              "             ':': 3,\n",
              "             'CC': 8,\n",
              "             'CD': 9,\n",
              "             'DT': 10,\n",
              "             'EX': 11,\n",
              "             'FW': 12,\n",
              "             'IN': 13,\n",
              "             'JJ': 14,\n",
              "             'JJR': 15,\n",
              "             'JJS': 16,\n",
              "             'LS': 18,\n",
              "             'MD': 19,\n",
              "             'NN': 20,\n",
              "             'NNP': 21,\n",
              "             'NNPS': 22,\n",
              "             'NNS': 23,\n",
              "             'O': 0,\n",
              "             'PDT': 24,\n",
              "             'POS': 25,\n",
              "             'PRP': 26,\n",
              "             'PRP$': 27,\n",
              "             'RB': 28,\n",
              "             'RBR': 29,\n",
              "             'RBS': 30,\n",
              "             'RP': 31,\n",
              "             'SYM': 33,\n",
              "             'TO': 34,\n",
              "             'UH': 35,\n",
              "             'VB': 36,\n",
              "             'VBD': 37,\n",
              "             'VBG': 38,\n",
              "             'VBN': 39,\n",
              "             'VBP': 40,\n",
              "             'VBZ': 41,\n",
              "             'WDT': 42,\n",
              "             'WP': 43,\n",
              "             'WP$': 44,\n",
              "             'WRB': 45,\n",
              "             '``': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yKJmAl0WUTA",
        "outputId": "a44e7af9-08b2-402f-db0a-c890caefc96a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{7: '#',\n",
              " 6: '$',\n",
              " 5: \"''\",\n",
              " 2: ',',\n",
              " 17: '-LRB-',\n",
              " 32: '-RRB-',\n",
              " 4: '.',\n",
              " 3: ':',\n",
              " 8: 'CC',\n",
              " 9: 'CD',\n",
              " 10: 'DT',\n",
              " 11: 'EX',\n",
              " 12: 'FW',\n",
              " 13: 'IN',\n",
              " 14: 'JJ',\n",
              " 15: 'JJR',\n",
              " 16: 'JJS',\n",
              " 18: 'LS',\n",
              " 19: 'MD',\n",
              " 20: 'NN',\n",
              " 21: 'NNP',\n",
              " 22: 'NNPS',\n",
              " 23: 'NNS',\n",
              " 0: 'O',\n",
              " 24: 'PDT',\n",
              " 25: 'POS',\n",
              " 26: 'PRP',\n",
              " 27: 'PRP$',\n",
              " 28: 'RB',\n",
              " 29: 'RBR',\n",
              " 30: 'RBS',\n",
              " 31: 'RP',\n",
              " 33: 'SYM',\n",
              " 34: 'TO',\n",
              " 35: 'UH',\n",
              " 36: 'VB',\n",
              " 37: 'VBD',\n",
              " 38: 'VBG',\n",
              " 39: 'VBN',\n",
              " 40: 'VBP',\n",
              " 41: 'VBZ',\n",
              " 42: 'WDT',\n",
              " 43: 'WP',\n",
              " 44: 'WP$',\n",
              " 45: 'WRB',\n",
              " 1: '``'}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PosTagging_Dataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 sentences: List[List[str]],\n",
        "                 tags: List[List[str]],\n",
        "                 tokenizer,\n",
        "                 label2id,\n",
        "                 max_len=MAX_LEN\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label2id = label2id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_token = self.sentences[idx]\n",
        "        label_token = self.tags[idx]\n",
        "\n",
        "        input_token = self.tokenizer.convert_tokens_to_ids(input_token)\n",
        "        attention_mask = [1] * len(input_token)\n",
        "        labels = [self.label2id[token] for token in label_token]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": self.pad_and_truncate(input_token, pad_id=self.tokenizer.pad_token_id),\n",
        "            \"labels\": self.pad_and_truncate(labels, pad_id=self.label2id[\"0\"]),\n",
        "            \"attention_mask\": self.pad_and_truncate(attention_mask, pad_id=0)\n",
        "        }\n",
        "\n",
        "    def pad_and_truncate(self, inputs: List[int], pad_id: int):\n",
        "        if len(inputs) < self.max_len:\n",
        "            padded_inputs = inputs + [pad_id] * (self.max_len - len(inputs))\n",
        "        else:\n",
        "            padded_inputs = inputs[:self.max_len]\n",
        "        return torch.as_tensor(padded_inputs)"
      ],
      "metadata": {
        "id": "nx3drMiZTgAD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PosTagging_Dataset(train_sentences, train_tags, tokenizer, label2id)\n",
        "val_dataset = PosTagging_Dataset(valid_sentences, valid_tags, tokenizer, label2id)\n",
        "test_dataset = PosTagging_Dataset(test_sentences, test_tags, tokenizer, label2id)"
      ],
      "metadata": {
        "id": "JzhJ_G7YcxLN"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF_ZkHAjiQ_v",
        "outputId": "933c528a-3e5c-4bc9-b5d1-944cd6ad40f7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([10357, 53306, 10105, 17936, 10114, 15767,   119,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0]),\n",
              " 'labels': tensor([26, 41, 10, 20, 34,  9,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Pspq4XNuj0zl",
        "outputId": "5a1f6bba-5a9d-4cb0-ba4b-b3fbe9016602"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "ignore_label = len(label2id)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    mask = labels != ignore_label\n",
        "    predictions = np.argmax(predictions, axis=-1)\n",
        "    return accuracy.compute(predictions=predictions[mask], references=labels[mask])"
      ],
      "metadata": {
        "id": "k5eIg6IOlHuk"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"out_dir\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jZBtE9notAT",
        "outputId": "5fd4a717-3a81-4b82-8fab-c1370f149917"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/tmp/ipython-input-2635477649.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QOn2hCF9zPyx",
        "outputId": "2255de6b-d368-4566-9a37-6ff169587d27"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1720/1720 29:24, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.036446</td>\n",
              "      <td>0.990011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.030142</td>\n",
              "      <td>0.991457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.140800</td>\n",
              "      <td>0.026635</td>\n",
              "      <td>0.992375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.140800</td>\n",
              "      <td>0.024801</td>\n",
              "      <td>0.992790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.140800</td>\n",
              "      <td>0.023979</td>\n",
              "      <td>0.993098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.025100</td>\n",
              "      <td>0.023291</td>\n",
              "      <td>0.993192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.025100</td>\n",
              "      <td>0.022991</td>\n",
              "      <td>0.993305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.025100</td>\n",
              "      <td>0.022854</td>\n",
              "      <td>0.993337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.019900</td>\n",
              "      <td>0.022744</td>\n",
              "      <td>0.993443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.019900</td>\n",
              "      <td>0.022718</td>\n",
              "      <td>0.993425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1720, training_loss=0.056396062984022985, metrics={'train_runtime': 1765.6443, 'train_samples_per_second': 15.513, 'train_steps_per_second': 0.974, 'total_flos': 3789641345256360.0, 'train_loss': 0.056396062984022985, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}