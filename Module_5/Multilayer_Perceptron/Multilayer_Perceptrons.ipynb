{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64087d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f69fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 59\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b90097",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0099ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './Content/Auto_MPG_data.csv'\n",
    "dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ffb8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns = 'MPG').values\n",
    "y = dataset['MPG'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57fabf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9) (392,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "725e6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "test_size = 0.125\n",
    "is_shuffle = True\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y,\n",
    "            test_size = val_size,\n",
    "            random_state = random_state,\n",
    "            shuffle = is_shuffle\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (\n",
    "            X_train, y_train,\n",
    "            test_size = test_size,\n",
    "            random_state = random_state,\n",
    "            shuffle = is_shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33db982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_val = normalizer.transform(X_val)\n",
    "X_test = normalizer.transform(X_test)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype = torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype = torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype = torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce997afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__ (self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc444142",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size = batch_size,\n",
    "                            shuffle = True)\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                            batch_size = batch_size,\n",
    "                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "785c96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dims, hidden_dims)\n",
    "        self.linear2 = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.output = nn.Linear(hidden_dims, output_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        out = self.output(x)\n",
    "        return out.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "637f525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = X_train.shape[1]\n",
    "output_dims = 1\n",
    "hidden_dims = 64\n",
    "\n",
    "model = MLP(input_dims = input_dims,\n",
    "            hidden_dims = hidden_dims,\n",
    "            output_dims = output_dims).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff7399cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a87eaa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squared(y_true, y_pred):\n",
    "    y_true = torch.Tensor(y_true).to(device)\n",
    "    y_pred = torch.Tensor(y_pred).to(device)\n",
    "    mean_true = torch.mean(y_true)\n",
    "    ss_tot = torch.sum((y_true - mean_true)**2)\n",
    "    ss_res = torch.sum((y_true - y_pred)**2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1c11f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH1:\tTraining loss:  282.770\tValidation loss:  88.670\n",
      "\n",
      "EPOCH2:\tTraining loss:  137.635\tValidation loss:  72.292\n",
      "\n",
      "EPOCH3:\tTraining loss:  71.239\tValidation loss:  19.697\n",
      "\n",
      "EPOCH4:\tTraining loss:  24.235\tValidation loss:  166.765\n",
      "\n",
      "EPOCH5:\tTraining loss:  89.885\tValidation loss:  19.714\n",
      "\n",
      "EPOCH6:\tTraining loss:  17.991\tValidation loss:  17.099\n",
      "\n",
      "EPOCH7:\tTraining loss:  20.454\tValidation loss:  9.154\n",
      "\n",
      "EPOCH8:\tTraining loss:  38.400\tValidation loss:  31.255\n",
      "\n",
      "EPOCH9:\tTraining loss:  19.581\tValidation loss:  32.197\n",
      "\n",
      "EPOCH10:\tTraining loss:  21.662\tValidation loss:  45.824\n",
      "\n",
      "EPOCH11:\tTraining loss:  31.023\tValidation loss:  22.099\n",
      "\n",
      "EPOCH12:\tTraining loss:  10.140\tValidation loss:  5.276\n",
      "\n",
      "EPOCH13:\tTraining loss:  16.154\tValidation loss:  13.905\n",
      "\n",
      "EPOCH14:\tTraining loss:  12.077\tValidation loss:  12.747\n",
      "\n",
      "EPOCH15:\tTraining loss:  14.311\tValidation loss:  8.573\n",
      "\n",
      "EPOCH16:\tTraining loss:  10.834\tValidation loss:  19.190\n",
      "\n",
      "EPOCH17:\tTraining loss:  12.288\tValidation loss:  14.394\n",
      "\n",
      "EPOCH18:\tTraining loss:  15.500\tValidation loss:  13.489\n",
      "\n",
      "EPOCH19:\tTraining loss:  15.559\tValidation loss:  5.416\n",
      "\n",
      "EPOCH20:\tTraining loss:  7.234\tValidation loss:  5.239\n",
      "\n",
      "EPOCH21:\tTraining loss:  8.682\tValidation loss:  4.782\n",
      "\n",
      "EPOCH22:\tTraining loss:  6.132\tValidation loss:  5.724\n",
      "\n",
      "EPOCH23:\tTraining loss:  10.291\tValidation loss:  51.771\n",
      "\n",
      "EPOCH24:\tTraining loss:  10.923\tValidation loss:  15.496\n",
      "\n",
      "EPOCH25:\tTraining loss:  8.910\tValidation loss:  8.620\n",
      "\n",
      "EPOCH26:\tTraining loss:  9.996\tValidation loss:  6.627\n",
      "\n",
      "EPOCH27:\tTraining loss:  6.162\tValidation loss:  6.821\n",
      "\n",
      "EPOCH28:\tTraining loss:  10.251\tValidation loss:  5.076\n",
      "\n",
      "EPOCH29:\tTraining loss:  6.470\tValidation loss:  11.247\n",
      "\n",
      "EPOCH30:\tTraining loss:  17.236\tValidation loss:  4.678\n",
      "\n",
      "EPOCH31:\tTraining loss:  7.664\tValidation loss:  5.823\n",
      "\n",
      "EPOCH32:\tTraining loss:  6.757\tValidation loss:  5.928\n",
      "\n",
      "EPOCH33:\tTraining loss:  7.339\tValidation loss:  4.633\n",
      "\n",
      "EPOCH34:\tTraining loss:  6.739\tValidation loss:  6.404\n",
      "\n",
      "EPOCH35:\tTraining loss:  7.288\tValidation loss:  6.279\n",
      "\n",
      "EPOCH36:\tTraining loss:  5.746\tValidation loss:  5.776\n",
      "\n",
      "EPOCH37:\tTraining loss:  5.977\tValidation loss:  6.211\n",
      "\n",
      "EPOCH38:\tTraining loss:  7.130\tValidation loss:  10.169\n",
      "\n",
      "EPOCH39:\tTraining loss:  7.617\tValidation loss:  14.393\n",
      "\n",
      "EPOCH40:\tTraining loss:  7.366\tValidation loss:  5.675\n",
      "\n",
      "EPOCH41:\tTraining loss:  5.737\tValidation loss:  18.630\n",
      "\n",
      "EPOCH42:\tTraining loss:  7.039\tValidation loss:  5.456\n",
      "\n",
      "EPOCH43:\tTraining loss:  7.575\tValidation loss:  28.341\n",
      "\n",
      "EPOCH44:\tTraining loss:  9.710\tValidation loss:  10.858\n",
      "\n",
      "EPOCH45:\tTraining loss:  6.519\tValidation loss:  4.844\n",
      "\n",
      "EPOCH46:\tTraining loss:  8.101\tValidation loss:  7.027\n",
      "\n",
      "EPOCH47:\tTraining loss:  6.216\tValidation loss:  6.157\n",
      "\n",
      "EPOCH48:\tTraining loss:  5.312\tValidation loss:  6.184\n",
      "\n",
      "EPOCH49:\tTraining loss:  6.614\tValidation loss:  10.023\n",
      "\n",
      "EPOCH50:\tTraining loss:  6.477\tValidation loss:  11.434\n",
      "\n",
      "EPOCH51:\tTraining loss:  7.598\tValidation loss:  7.062\n",
      "\n",
      "EPOCH52:\tTraining loss:  10.515\tValidation loss:  5.242\n",
      "\n",
      "EPOCH53:\tTraining loss:  7.262\tValidation loss:  4.912\n",
      "\n",
      "EPOCH54:\tTraining loss:  6.507\tValidation loss:  5.422\n",
      "\n",
      "EPOCH55:\tTraining loss:  5.301\tValidation loss:  5.158\n",
      "\n",
      "EPOCH56:\tTraining loss:  5.488\tValidation loss:  6.168\n",
      "\n",
      "EPOCH57:\tTraining loss:  7.399\tValidation loss:  6.897\n",
      "\n",
      "EPOCH58:\tTraining loss:  6.467\tValidation loss:  16.789\n",
      "\n",
      "EPOCH59:\tTraining loss:  7.093\tValidation loss:  8.161\n",
      "\n",
      "EPOCH60:\tTraining loss:  5.556\tValidation loss:  5.017\n",
      "\n",
      "EPOCH61:\tTraining loss:  5.534\tValidation loss:  7.621\n",
      "\n",
      "EPOCH62:\tTraining loss:  9.426\tValidation loss:  4.721\n",
      "\n",
      "EPOCH63:\tTraining loss:  6.600\tValidation loss:  14.011\n",
      "\n",
      "EPOCH64:\tTraining loss:  6.094\tValidation loss:  6.040\n",
      "\n",
      "EPOCH65:\tTraining loss:  8.167\tValidation loss:  5.401\n",
      "\n",
      "EPOCH66:\tTraining loss:  5.275\tValidation loss:  5.189\n",
      "\n",
      "EPOCH67:\tTraining loss:  5.741\tValidation loss:  6.415\n",
      "\n",
      "EPOCH68:\tTraining loss:  11.043\tValidation loss:  7.501\n",
      "\n",
      "EPOCH69:\tTraining loss:  6.949\tValidation loss:  8.959\n",
      "\n",
      "EPOCH70:\tTraining loss:  6.058\tValidation loss:  5.352\n",
      "\n",
      "EPOCH71:\tTraining loss:  5.061\tValidation loss:  4.742\n",
      "\n",
      "EPOCH72:\tTraining loss:  5.909\tValidation loss:  9.186\n",
      "\n",
      "EPOCH73:\tTraining loss:  6.737\tValidation loss:  10.368\n",
      "\n",
      "EPOCH74:\tTraining loss:  6.271\tValidation loss:  5.313\n",
      "\n",
      "EPOCH75:\tTraining loss:  5.407\tValidation loss:  17.910\n",
      "\n",
      "EPOCH76:\tTraining loss:  7.440\tValidation loss:  18.028\n",
      "\n",
      "EPOCH77:\tTraining loss:  10.871\tValidation loss:  7.128\n",
      "\n",
      "EPOCH78:\tTraining loss:  6.876\tValidation loss:  5.344\n",
      "\n",
      "EPOCH79:\tTraining loss:  5.900\tValidation loss:  11.931\n",
      "\n",
      "EPOCH80:\tTraining loss:  8.111\tValidation loss:  5.605\n",
      "\n",
      "EPOCH81:\tTraining loss:  10.663\tValidation loss:  6.507\n",
      "\n",
      "EPOCH82:\tTraining loss:  5.715\tValidation loss:  5.687\n",
      "\n",
      "EPOCH83:\tTraining loss:  5.457\tValidation loss:  8.128\n",
      "\n",
      "EPOCH84:\tTraining loss:  5.171\tValidation loss:  5.307\n",
      "\n",
      "EPOCH85:\tTraining loss:  4.884\tValidation loss:  6.696\n",
      "\n",
      "EPOCH86:\tTraining loss:  4.854\tValidation loss:  6.557\n",
      "\n",
      "EPOCH87:\tTraining loss:  5.115\tValidation loss:  7.695\n",
      "\n",
      "EPOCH88:\tTraining loss:  5.114\tValidation loss:  5.099\n",
      "\n",
      "EPOCH89:\tTraining loss:  4.872\tValidation loss:  5.391\n",
      "\n",
      "EPOCH90:\tTraining loss:  6.415\tValidation loss:  5.476\n",
      "\n",
      "EPOCH91:\tTraining loss:  5.278\tValidation loss:  8.061\n",
      "\n",
      "EPOCH92:\tTraining loss:  7.236\tValidation loss:  5.575\n",
      "\n",
      "EPOCH93:\tTraining loss:  6.272\tValidation loss:  5.292\n",
      "\n",
      "EPOCH94:\tTraining loss:  8.881\tValidation loss:  7.097\n",
      "\n",
      "EPOCH95:\tTraining loss:  6.304\tValidation loss:  6.152\n",
      "\n",
      "EPOCH96:\tTraining loss:  8.173\tValidation loss:  18.792\n",
      "\n",
      "EPOCH97:\tTraining loss:  6.927\tValidation loss:  9.855\n",
      "\n",
      "EPOCH98:\tTraining loss:  6.748\tValidation loss:  7.787\n",
      "\n",
      "EPOCH99:\tTraining loss:  6.225\tValidation loss:  5.003\n",
      "\n",
      "EPOCH100:\tTraining loss:  5.901\tValidation loss:  4.899\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_r2 = []\n",
    "val_r2 = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_target = []\n",
    "    val_target = []\n",
    "    train_predict = []\n",
    "    val_predict = []\n",
    "    model.train()\n",
    "    for X_samples, y_samples in train_loader:\n",
    "        X_samples = X_samples.to(device)\n",
    "        y_samples = y_samples.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_samples)\n",
    "        train_predict += outputs.tolist()\n",
    "        train_target += y_samples.tolist()\n",
    "        loss = criterion(outputs, y_samples)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_r2.append(r_squared(train_target, train_predict))\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_samples, y_samples in val_loader:\n",
    "            X_samples = X_samples.to(device)\n",
    "            y_samples = y_samples.to(device)\n",
    "            outputs = model(X_samples)\n",
    "            val_predict += outputs.tolist()\n",
    "            val_target += y_samples.tolist()\n",
    "            loss = criterion(outputs, y_samples)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_r2.append(r_squared(val_target, val_predict))\n",
    "    print(f'\\nEPOCH{epoch + 1}:\\tTraining loss: {train_loss: .3f}\\tValidation loss: {val_loss: .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f7e8e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test set:\n",
      "R2: 0.8374040126800537\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = model(X_test)\n",
    "    test_set_r2 = r_squared(y_hat, y_test)\n",
    "    print('Evaluation on test set:')\n",
    "    print(f'R2: {test_set_r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
